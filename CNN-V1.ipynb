{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of EIP4-S5-Assignment 5 -ResNet50-PersonAttributes.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmaruthi/Assignment5/blob/master/CNN-V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -q \"/content/gdrive/My Drive/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "\n",
        "#from keras.applications import VGG16\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import os\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.resnet50 import ResNet50\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()   # To Return the top 5 rows of the data frame "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aegQRRcWpVV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.describe()  # To get the summary of statistics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll94zTv6w5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=32, shuffle=True,augmentation=None):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.augmentation = augmentation\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "#       'items' is a df generated from main df based on batch_size. \n",
        "#       items.iterrows() will take item['image_path'] and fetch it to cv2.imread().\n",
        "#       cv2.imread() will convert it to a numpy array which can be used by python\n",
        "        image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "        # target is a dictionary with all gender cols counted against key 'gender_output' and so on.\n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ybL-WdltZfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cut out \n",
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating Train and Validation data frames \n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m15DLyF2ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display top two rows from train and val data frames \n",
        "train_df.head(2) \n",
        "val_df.head(2)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "train_gen = PersonDataGenerator(train_df, batch_size=32, \n",
        "                                augmentation=ImageDataGenerator(rescale=1./255,\n",
        "                                                                featurewise_center=True,\n",
        "                                                                featurewise_std_normalization=True,\n",
        "                                                                horizontal_flip=True,\n",
        "                                                                width_shift_range=0.2,\n",
        "                                                                height_shift_range=0.2,\n",
        "                                                                fill_mode='nearest',\n",
        "                                                                rotation_range=90,\n",
        "                                                                preprocessing_function=get_random_eraser(v_l=1, v_h=1)))\n",
        "\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=32, shuffle=False,\n",
        "                                augmentation=ImageDataGenerator(rescale=1./255,\n",
        "                                                                featurewise_center=True,\n",
        "                                                                featurewise_std_normalization=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "# targets is a dictionary that we get from person data generator.\n",
        "# k will get key value 'age_output' which will be split to get 'age' only\n",
        "# v will get value of disctionary. We will take how many columns are there in v to understand classes within each class. eg: v.shape[1] will be 2\n",
        "# for key 'gender_output' because there are 2 sub-categories 'male' & 'female'\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3tCjqf03W-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To check if images are getting read correctly\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('resized/1.jpg',0)\n",
        "cv2_imshow(img)\n",
        "print('type::',type(img))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03W8Pagg_Ppp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using Sequential model \n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import os\n",
        "\n",
        "backbone = Sequential()\n",
        "\n",
        "backbone.add(Convolution2D(16, (3, 3),use_bias=False,input_shape=(224, 224, 3))) #222\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(Convolution2D(16, (3, 3),use_bias=False)) #220\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(Convolution2D(32, (3, 3),use_bias=False)) #218\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(Convolution2D(32, (3, 3),use_bias=False)) #216\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(Convolution2D(64, (3, 3),use_bias=False)) #214\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(Convolution2D(64, (3, 3),use_bias=False)) #212\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(MaxPooling2D(pool_size=(2, 2)))  #106\n",
        "\n",
        "backbone.add(Convolution2D(64, (3, 3),use_bias=False)) #104\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(Convolution2D(64, (3, 3),use_bias=False)) #102\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(Convolution2D(96, (3, 3),use_bias=False)) #100\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(Convolution2D(96, (3, 3),use_bias=False)) #98\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(Convolution2D(96, (3, 3),use_bias=False)) #96\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(MaxPooling2D(pool_size=(2, 2)))  #48\n",
        "\n",
        "backbone.add(Convolution2D(128, (3, 3),use_bias=False)) #46\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(Convolution2D(128, (3, 3),use_bias=False)) #44\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(Convolution2D(128, (3, 3),use_bias=False)) #42\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(Convolution2D(128, (3, 3),use_bias=False)) #40\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(Convolution2D(128, (3, 3),use_bias=False)) #38\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(MaxPooling2D(pool_size=(2, 2)))  #19\n",
        "\n",
        "backbone.add(Convolution2D(128, (3, 3),strides=(2,2))) #9\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "\n",
        "backbone.add(Convolution2D(128, (3, 3),dilation_rate=(2, 2))) #5\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "backbone.add(GlobalAveragePooling2D(name='avg_pool'))\n",
        "\n",
        "neck = backbone.output\n",
        "\n",
        "def build_tower(in_layer):\n",
        "    return neck\n",
        "\n",
        "def build_head(name, in_layer):\n",
        "    return Dense(\n",
        "        num_units[name], activation=\"softmax\", name=f\"{name}_output\"\n",
        "    )(in_layer)\n",
        "\n",
        "# heads\n",
        "gender = build_head(\"gender\", build_tower(neck))\n",
        "image_quality = build_head(\"image_quality\", build_tower(neck))\n",
        "age = build_head(\"age\", build_tower(neck))\n",
        "weight = build_head(\"weight\", build_tower(neck))\n",
        "bag = build_head(\"bag\", build_tower(neck))\n",
        "footwear = build_head(\"footwear\", build_tower(neck))\n",
        "emotion = build_head(\"emotion\", build_tower(neck))\n",
        "pose = build_head(\"pose\", build_tower(neck))\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    inputs=backbone.input, \n",
        "    outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XXgNIsENvmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "#plot_model(model, show_shapes=True,to_file='model.png')\n",
        "plot_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfPG9C2eA1zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.004 * 1/(1 + 0.319 * epoch), 10)\n",
        "opt = SGD(lr=0.003, momentum=0.9)\n",
        "#opt = SGD(momentum=0.5)\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss = \"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw2ZRIQ7BW-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=32, epochs=10)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpxv41EyNmN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        " #  use_multiprocessing=False,\n",
        " #  workers=1, \n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    callbacks=[LearningRateScheduler(scheduler,verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM6n4pEYO0fQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H72RHXbdOzmM",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI1hJb4qM6OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}